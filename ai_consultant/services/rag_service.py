"""
üîç RAG (Retrieval-Augmented Generation) Service
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
"""

import os
import json
import logging
import uuid
from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime, timedelta
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.tokenize import sent_tokenize

# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö NLTK –¥–∞–Ω–Ω—ã—Ö
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

from django.conf import settings
from django.core.cache import cache
from openai import OpenAI

logger = logging.getLogger(__name__)


class RAGService:
    """
    üöÄ –°–µ—Ä–≤–∏—Å RAG –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∑–∞–ø—Ä–æ—Å–æ–≤ –ò–ò-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞
    """

    def __init__(self):
        self.model_name = getattr(settings, 'RAG_EMBEDDING_MODEL', 'all-MiniLM-L6-v2')
        self.embedding_model = SentenceTransformer(self.model_name)
        self.openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path=getattr(settings, 'CHROMA_DB_PATH', './chroma_db')
        )

        # –ö–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–Ω–∞–Ω–∏–π
        self.collections = {
            'clubs': None,
            'documentation': None,
            'faq': None,
            'history': None,
            'events': None
        }

        # –ö—ç—à –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.embedding_cache = {}
        self._init_collections()

    def _init_collections(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π ChromaDB"""
        try:
            for collection_name in self.collections.keys():
                try:
                    self.collections[collection_name] = self.chroma_client.get_or_create_collection(
                        name=collection_name,
                        metadata={"description": f"UnitySphere {collection_name} knowledge base"}
                    )
                    logger.info(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}' –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}': {e}")

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ RAG —Å–µ—Ä–≤–∏—Å–∞: {e}")

    def get_embedding(self, text: str) -> np.ndarray:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if text in self.embedding_cache:
            return self.embedding_cache[text]

        try:
            embedding = self.embedding_model.encode(text, convert_to_numpy=True)
            self.embedding_cache[text] = embedding
            return embedding
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return np.zeros(384)  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è MiniLM

    def add_document(self, collection_name: str, text: str, metadata: Dict[str, Any] = None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É"""
        if collection_name not in self.collections:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {collection_name}")
            return False

        try:
            doc_id = str(uuid.uuid4())
            embedding = self.get_embedding(text).tolist()

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            if metadata is None:
                metadata = {}
            metadata.update({
                'created_at': datetime.now().isoformat(),
                'text_length': len(text),
                'collection': collection_name
            })

            self.collections[collection_name].add(
                embeddings=[embedding],
                documents=[text],
                metadatas=[metadata],
                ids=[doc_id]
            )

            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ {collection_name}: {doc_id[:8]}...")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False

    def search_similar(self, collection_name: str, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        if collection_name not in self.collections or not self.collections[collection_name]:
            logger.warning(f"‚ö†Ô∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞")
            return []

        try:
            query_embedding = self.get_embedding(query).tolist()

            results = self.collections[collection_name].query(
                query_embeddings=[query_embedding],
                n_results=min(n_results, 10)
            )

            formatted_results = []
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    'id': results['ids'][0][i],
                    'text': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i] if 'distances' in results else 0
                })

            return formatted_results

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ {collection_name}: {e}")
            return []

    def get_enhanced_context(self, query: str, user_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        üéØ –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        """
        context = {
            'query': query,
            'user_context': user_context or {},
            'retrieved_info': {},
            'confidence_scores': {},
            'total_docs_found': 0
        }

        # –ü–æ–∏—Å–∫ –≤ —Ä–∞–∑–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏—è—Ö
        search_queries = self._generate_search_queries(query)

        for collection_name in self.collections.keys():
            if not self.collections[collection_name]:
                continue

            all_results = []
            for search_query in search_queries:
                results = self.search_similar(collection_name, search_query, n_results=3)
                all_results.extend(results)

            # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
            unique_results = self._deduplicate_and_rank(all_results)

            if unique_results:
                context['retrieved_info'][collection_name] = unique_results[:3]  # –¢–æ–ø-3 –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                context['total_docs_found'] += len(unique_results)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        context['overall_confidence'] = self._calculate_overall_confidence(context)

        return context

    def _generate_search_queries(self, original_query: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        queries = [original_query]

        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
        keywords = {
            '–∫–ª—É–±': ['—Å–æ–æ–±—â–µ—Å—Ç–≤–æ', '–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ', '–≥—Ä—É–ø–ø–∞', '—Å–µ–∫—Ü–∏—è'],
            '—Å–æ–∑–¥–∞—Ç—å': ['–æ—Å–Ω–æ–≤–∞—Ç—å', '–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å', '–æ—Ç–∫—Ä—ã—Ç—å', '—É—á—Ä–µ–¥–∏—Ç—å'],
            '–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ': ['—Å–æ–±—ã—Ç–∏–µ', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—å', '–≤—Å—Ç—Ä–µ—á–∞', '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è'],
            '–≤–æ–ø—Ä–æ—Å': ['–ø—Ä–æ–±–ª–µ–º–∞', '–ø–æ–º–æ—â—å', '–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è', '—Å–æ–≤–µ—Ç']
        }

        for key, synonyms in keywords.items():
            if key.lower() in original_query.lower():
                for synonym in synonyms:
                    expanded_query = original_query.lower().replace(key.lower(), synonym)
                    if expanded_query not in queries:
                        queries.append(expanded_query)

        return queries[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –∑–∞–ø—Ä–æ—Å–æ–≤

    def _deduplicate_and_rank(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not results:
            return []

        # –ü—Ä–æ—Å—Ç–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É
        seen_texts = set()
        unique_results = []

        for result in results:
            text_lower = result['text'].lower().strip()
            if text_lower not in seen_texts and len(text_lower) > 20:
                seen_texts.add(text_lower)
                unique_results.append(result)

        # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
        unique_results.sort(key=lambda x: x.get('distance', 1.0))

        return unique_results

    def _calculate_overall_confidence(self, context: Dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if not context['retrieved_info']:
            return 0.0

        total_confidence = 0.0
        total_docs = 0

        for collection_name, docs in context['retrieved_info'].items():
            for doc in docs:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è distance –≤ confidence (1 - normalized_distance)
                distance = doc.get('distance', 1.0)
                confidence = max(0.0, min(1.0, 1.0 - distance))
                total_confidence += confidence
                total_docs += 1

        return total_confidence / total_docs if total_docs > 0 else 0.0

    def format_context_for_prompt(self, context: Dict[str, Any]) -> str:
        """
        üìù –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        """
        if not context['retrieved_info']:
            return "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –û—Ç–≤–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π –æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ UnitySphere."

        formatted_sections = []

        for collection_name, docs in context['retrieved_info'].items():
            if not docs:
                continue

            section_title = {
                'clubs': 'üè¢ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª—É–±–∞—Ö',
                'documentation': 'üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã',
                'faq': '‚ùì –ß–∞—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã',
                'history': 'üí¨ –ò—Å—Ç–æ—Ä–∏—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π',
                'events': 'üìÖ –ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ —Å–æ–±—ã—Ç–∏—è'
            }.get(collection_name, f'üìÑ {collection_name.title()}')

            section_content = f"**{section_title}:**\n"

            for i, doc in enumerate(docs, 1):
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
                text = doc['text'][:500]
                if len(doc['text']) > 500:
                    text += "..."

                relevance_score = 1.0 - doc.get('distance', 0.5)
                section_content += f"{i}. {text} (–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_score:.2f})\n"

            formatted_sections.append(section_content)

        # –û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        overall_conf = context.get('overall_confidence', 0.0)
        confidence_text = f"**–û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {overall_conf:.2f}**"

        # –°–±–æ—Ä–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        final_context = f"""
üîç **–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π UnitySphere:**

{chr(10).join(formatted_sections)}

{confidence_text}

–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ—á–Ω–æ–≥–æ –∏ contextual –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
"""

        return final_context

    def index_club_data(self):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –∫–ª—É–±–∞—Ö"""
        try:
            from clubs.models import Club

            clubs = Club.objects.filter(is_active=True)[:100]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞

            for club in clubs:
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–ª—É–±–∞
                club_text = f"""
                –ö–ª—É–±: {club.name}
                –û–ø–∏—Å–∞–Ω–∏–µ: {club.description or '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'}
                –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {club.category.name if club.category else '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}
                –¢–µ–ª–µ—Ñ–æ–Ω: {club.phone or '–ù–µ —É–∫–∞–∑–∞–Ω'}
                Email: {club.email or '–ù–µ —É–∫–∞–∑–∞–Ω'}
                """

                metadata = {
                    'club_id': club.id,
                    'club_name': club.name,
                    'category': club.category.name if club.category else None,
                    'is_active': club.is_active
                }

                self.add_document('clubs', club_text.strip(), metadata)

            logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –∫–ª—É–±–æ–≤: {len(clubs)}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–ª—É–±–æ–≤: {e}")

    def index_documentation(self):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
        docs_to_add = [
            {
                'text': '''
                UnitySphere - —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–ª—É–±–∞–º–∏ –∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º–∏.
                –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª—É–±–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ: –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–æ—Ä–º—É, —É–∫–∞–∑–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ, –æ–ø–∏—Å–∞–Ω–∏–µ,
                –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞.
                ''',
                'metadata': {'type': 'getting_started', 'priority': 'high'}
            },
            {
                'text': '''
                –ü—Ä–∞–≤–∏–ª–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª—É–±–∞ –Ω–∞ UnitySphere:
                1. –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª—É–±–∞
                2. –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                3. –ö–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Ç–µ–ª–µ—Ñ–æ–Ω, email)
                4. –í—ã–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–ª—É–±–∞
                5. –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ—Ç–∏–ø–∞ –∫–ª—É–±–∞
                6. –ú–æ–¥–µ—Ä–∞—Ü–∏—è –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤
                ''',
                'metadata': {'type': 'club_creation_rules', 'priority': 'high'}
            },
            {
                'text': '''
                Frequently Asked Questions:
                Q: –ö–∞–∫ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∫ –∫–ª—É–±—É?
                A: –ù–∞–π–¥–∏—Ç–µ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–π –∫–ª—É–±, –Ω–∞–∂–º–∏—Ç–µ "–ü—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è" –∏ –æ–∂–∏–¥–∞–π—Ç–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.

                Q: –ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ?
                A: –í –ª–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ –∫–ª—É–±–∞ –≤—ã–±–µ—Ä–∏—Ç–µ "–°–æ–∑–¥–∞—Ç—å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ", –∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É –∏ –æ–ø—É–±–ª–∏–∫—É–π—Ç–µ.
                ''',
                'metadata': {'type': 'faq', 'priority': 'medium'}
            }
        ]

        for doc in docs_to_add:
            self.add_document('documentation', doc['text'], doc['metadata'])
            self.add_document('faq', doc['text'], doc['metadata'])

        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs_to_add)}")

    def rebuild_index(self):
        """–ü–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å –Ω—É–ª—è"""
        logger.info("üîÑ –ü–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ RAG...")

        # –û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π
        for collection_name, collection in self.collections.items():
            if collection:
                try:
                    collection.delete()
                    logger.info(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –æ—á–∏—â–µ–Ω–∞")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ {collection_name}: {e}")

        # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._init_collections()

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        self.index_documentation()
        self.index_club_data()

        logger.info("‚úÖ –ü–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä RAG —Å–µ—Ä–≤–∏—Å–∞
rag_service = None


def get_rag_service():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ RAG —Å–µ—Ä–≤–∏—Å–∞"""
    global rag_service
    if rag_service is None:
        rag_service = RAGService()
    return rag_service