"""
üîç RAG (Retrieval-Augmented Generation) —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ò–ò-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from django.core.cache import cache
from django.conf import settings
import json
import re
from datetime import datetime, timedelta

from ..knowledge.platform_knowledge_base import platform_knowledge

logger = logging.getLogger(__name__)


class RAGSystem:
    """
    –°–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
    """

    def __init__(self):
        self.cache_timeout = getattr(settings, 'RAG_CACHE_TIMEOUT', 3600)  # 1 —á–∞—Å
        self.similarity_threshold = 0.3

    # =====================================================
    # –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò RAG
    # =====================================================

    def get_relevant_context(self, query: str, agent_type: str = "orchestrator",
                           user_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞

        Args:
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            agent_type: –¢–∏–ø –∞–≥–µ–Ω—Ç–∞
            user_context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        try:
            # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
            normalized_query = self._normalize_query(query)

            # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
            intent = self._classify_intent(normalized_query)

            # 3. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            context_data = self._retrieve_relevant_info(normalized_query, intent, agent_type)

            # 4. –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if user_context:
                context_data.update(self._enrich_with_user_context(user_context, agent_type))

            # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            formatted_context = self._format_context_for_agent(context_data, agent_type)

            # 6. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            cache_key = f"rag_context_{hash(query)}_{agent_type}"
            cache.set(cache_key, formatted_context, self.cache_timeout)

            return {
                "success": True,
                "context": formatted_context,
                "intent": intent,
                "sources": context_data.get("sources", []),
                "query_analysis": {
                    "original": query,
                    "normalized": normalized_query,
                    "keywords": self._extract_keywords(normalized_query)
                }
            }

        except Exception as e:
            logger.error(f"RAG system error: {e}", exc_info=True)
            return self._get_fallback_context(query, agent_type)

    # =====================================================
    # –ê–ù–ê–õ–ò–ó –ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ó–ê–ü–†–û–°–û–í
    # =====================================================

    def _normalize_query(self, query: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        normalized = query.lower().strip()

        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        normalized = re.sub(r'\s+', ' ', normalized)

        # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ (–∫—Ä–æ–º–µ –≤–∞–∂–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤)
        normalized = re.sub(r'[^\w\s\?\!]', ' ', normalized)

        # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π
        expansions = {
            '–∏—Ç': '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
            '–∞–π—Ç–∏': '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
            '—Å–º–º': '—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –º–µ–¥–∏–∞ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥',
            'pr': '–ø–∞–±–ª–∏–∫ —Ä–∏–ª–µ–π—à–Ω–∑',
            'hr': '—Ö—å—é–º–∞–Ω —Ä–µ—Å—É—Ä—Å',
            '—Å–µ–æ': '–ø–æ–∏—Å–∫–æ–≤–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è'
        }

        for abbr, expansion in expansions.items():
            normalized = normalized.replace(abbr, expansion)

        return normalized.strip()

    def _classify_intent(self, query: str) -> Dict[str, Any]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        intent_patterns = {
            "club_creation": {
                "keywords": ["—Å–æ–∑–¥–∞—Ç—å", "—Å–æ–∑–¥–∞–π", "—Ö–æ—á—É —Å–æ–∑–¥–∞—Ç—å", "—Å–æ–∑–¥–∞–Ω–∏–µ", "–Ω–æ–≤—ã–π –∫–ª—É–±", "—Å–æ–∑–¥–∞–º"],
                "weight": 0.8
            },
            "club_search": {
                "keywords": ["–Ω–∞–π–¥–∏", "–Ω–∞–π—Ç–∏", "–ø–æ–∏—Å–∫", "–∏—â—É", "–∫–∞–∫–æ–π", "–∫–∞–∫–∏–µ –µ—Å—Ç—å", "–ø–æ–∫–∞–∂–∏"],
                "weight": 0.7
            },
            "join_club": {
                "keywords": ["–≤—Å—Ç—É–ø–∏—Ç—å", "–≤—Å—Ç—É–ø–ª—é", "–∫–∞–∫ –≤—Å—Ç—É–ø–∏—Ç—å", "—Ö–æ—á—É –≤—Å—Ç—É–ø–∏—Ç—å", "–ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è"],
                "weight": 0.6
            },
            "learning": {
                "keywords": ["–Ω–∞—É—á–∏—Ç—å—Å—è", "–∏–∑—É—á–∏—Ç—å", "–æ–±—É—á–µ–Ω–∏–µ", "–∫—É—Ä—Å", "—Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è", "–Ω–∞–≤—ã–∫"],
                "weight": 0.7
            },
            "technical_help": {
                "keywords": ["–ø–æ–º–æ—â—å", "–ø—Ä–æ–±–ª–µ–º–∞", "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–æ—à–∏–±–∫–∞", "–≤–æ–ø—Ä–æ—Å", "–∫–∞–∫"],
                "weight": 0.6
            },
            "general_info": {
                "keywords": ["—á—Ç–æ —Ç–∞–∫–æ–µ", "—Ä–∞—Å—Å–∫–∞–∂–∏", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ", "—á—Ç–æ —ç—Ç–æ"],
                "weight": 0.5
            }
        }

        query_words = set(query.split())
        intent_scores = {}

        for intent_name, intent_data in intent_patterns.items():
            keywords = set(intent_data["keywords"])
            overlap = len(query_words & keywords)
            score = overlap / len(keywords) * intent_data["weight"]
            intent_scores[intent_name] = score

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        primary_intent = max(intent_scores.items(), key=lambda x: x[1])

        return {
            "primary_intent": primary_intent[0] if primary_intent[1] > 0 else "general",
            "confidence": primary_intent[1],
            "all_scores": intent_scores
        }

    def _extract_keywords(self, query: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""
        # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            '–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–æ', '–æ–±', '–æ—Ç', '–∫', '—É', '–∏–∑', '–∑–∞',
            '—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫–∞–∫–æ–π', '–∫–∞–∫–∞—è', '–∫–∞–∫–∏–µ',
            '—è', '—Ç—ã', '–æ–Ω', '–æ–Ω–∞', '–æ–Ω–∏', '–º—ã', '–≤—ã', '–º–µ–Ω—è', '—Ç–µ–±—è', '–µ–≥–æ', '–µ–µ',
            '—ç—Ç–æ—Ç', '—Ç–æ—Ç', '—ç—Ç–æ', '—Ç–æ—Ç', '—Ç–∞–∫–æ–π', '—Ç–∞–∫–∞—è', '—Ç–∞–∫–∏–µ', '–∑–¥–µ—Å—å', '—Ç–∞–º',
            '—Ö–æ—á—É', '–º–æ–≥—É', '–Ω–∞–¥–æ', '–Ω—É–∂–Ω–æ', '–±—É–¥—É', '–±—É–¥–µ—Ç', '–µ—Å—Ç—å', '–±—ã—Ç—å', '–±—ã–ª'
        }

        words = query.split()
        keywords = [word for word in words if word not in stop_words and len(word) > 2]

        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories = ["—Å–ø–æ—Ä—Ç", "—Ö–æ–±–±–∏", "–ø—Ä–æ—Ñ–µ—Å—Å–∏—è", "—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ", "–±–∏–∑–Ω–µ—Å", "it", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"]
        for category in categories:
            if category in query:
                keywords.append(category)

        return list(set(keywords))

    # =====================================================
    # –ü–û–ò–°–ö –†–ï–õ–ï–í–ê–ù–¢–ù–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ò
    # =====================================================

    def _retrieve_relevant_info(self, query: str, intent: Dict[str, Any],
                              agent_type: str) -> Dict[str, Any]:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        context = {}
        sources = []

        # 1. –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ
        if intent["primary_intent"] in ["general_info", "technical_help"]:
            context["platform_info"] = platform_knowledge.PLATFORM_INFO
            sources.append("platform_knowledge_base")

        # 2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
        categories_keywords = ["—Å–ø–æ—Ä—Ç", "—Ö–æ–±–±–∏", "–ø—Ä–æ—Ñ–µ—Å—Å–∏—è", "–∫–∞—Ç–µ–≥–æ—Ä–∏–∏"]
        if any(keyword in query for keyword in categories_keywords):
            context["categories"] = platform_knowledge.CATEGORIES
            sources.append("categories_database")

        # 3. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        if intent["primary_intent"] == "club_creation":
            context["create_club_instruction"] = platform_knowledge.get_instruction("create_club")
            sources.append("instructions_database")

        if intent["primary_intent"] == "join_club":
            context["join_club_instruction"] = platform_knowledge.get_instruction("join_club")
            sources.append("instructions_database")

        # 4. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        features_keywords = ["–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ", "—É—Å–ª—É–≥–∞", "–ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ", "–ø–æ–∏—Å–∫", "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ"]
        if any(keyword in query for keyword in features_keywords):
            context["platform_features"] = platform_knowledge.PLATFORM_FEATURES
            sources.append("features_database")

        # 5. –¶–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
        if intent["primary_intent"] in ["general_info", "club_search"]:
            context["value_propositions"] = platform_knowledge.VALUE_PROPOSITIONS
            sources.append("value_propositions")

        # 6. –°—Ç–∏–ª–∏ –æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        context["communication_style"] = platform_knowledge.get_communication_style(agent_type)

        # 7. –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã
        context["key_phrases"] = platform_knowledge.KEY_PHRASES

        # 8. –ò—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞ (–¥–ª—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏)
        if intent["primary_intent"] in ["general_info", "learning"]:
            context["success_stories"] = platform_knowledge.SUCCESS_STORIES[:2]  # –ü–µ—Ä–≤—ã–µ 2 –∏—Å—Ç–æ—Ä–∏–∏
            sources.append("success_stories")

        # 9. –ß–∞—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        if intent["primary_intent"] == "technical_help":
            context["faq"] = platform_knowledge.FAQ
            sources.append("faq_database")

        context["sources"] = sources
        return context

    def _enrich_with_user_context(self, user_context: Dict[str, Any],
                                 agent_type: str) -> Dict[str, Any]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        enriched = {}

        # –ì–µ–æ–ª–æ–∫–∞—Ü–∏—è
        if user_context.get("city"):
            enriched["user_city"] = user_context["city"]
            enriched["local_recommendations"] = self._get_local_recommendations(user_context["city"])

        # –ò–Ω—Ç–µ—Ä–µ—Å—ã
        if user_context.get("interests"):
            interests = user_context["interests"]
            enriched["personalized_categories"] = self._map_interests_to_categories(interests)

        # –ò—Å—Ç–æ—Ä–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        if user_context.get("interaction_history"):
            enriched="conversation_context" = self._analyze_conversation_history(
                user_context["interaction_history"]
            )

        # –£—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_context.get("skill_level"):
            enriched["adaptation_level"] = user_context["skill_level"]

        return enriched

    # =====================================================
    # –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ö–û–ù–¢–ï–ö–°–¢–ê –î–õ–Ø –ê–ì–ï–ù–¢–û–í
    # =====================================================

    def _format_context_for_agent(self, context_data: Dict[str, Any],
                                agent_type: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫–µ–Ω—Ç–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞"""
        formatted_sections = []

        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤)
        if "platform_info" in context_data:
            info = context_data["platform_info"]
            formatted_sections.append(
                f"üè¢ **–ü–õ–ê–¢–§–û–†–ú–ê:** {info['name']} ({info['country']})\n"
                f"üìã **–ú–ò–°–°–ò–Ø:** {info['mission']}\n"
                f"üéØ **–°–õ–û–ì–ê–ù:** {info['main_slogan']}"
            )

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
        if "categories" in context_data:
            formatted_sections.append("\nüè∑Ô∏è **–ö–ê–¢–ï–ì–û–†–ò–ò –ö–õ–£–ë–û–í:**")
            for cat_key, cat_data in context_data["categories"].items():
                formatted_sections.append(
                    f"{cat_data['emoji']} **{cat_data['name']}** - {cat_data['description']}\n"
                    f"   –ü—Ä–∏–º–µ—Ä—ã: {', '.join(cat_data['examples'][:3])}..."
                )

        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (–¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏—è)
        if "create_club_instruction" in context_data:
            instruction = context_data["create_club_instruction"]
            formatted_sections.append(
                f"\nüìù **–ò–ù–°–¢–†–£–ö–¶–ò–Ø –°–û–ó–î–ê–ù–ò–Ø –ö–õ–£–ë–ê:**\n"
                f"–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {', '.join([f['name'] for f in instruction['required_fields']])}"
            )

        # –¶–µ–Ω–Ω–æ—Å—Ç–∏ (–¥–ª—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏)
        if "value_propositions" in context_data:
            props = context_data["value_propositions"]
            formatted_sections.append(
                f"\n‚ú® **–¶–ï–ù–ù–û–°–¢–ò –ü–õ–ê–¢–§–û–†–ú–´:**\n" +
                "\n".join(f"‚Ä¢ {benefit}" for benefit in props['main_benefits'][:3])
            )

        # –ò—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞ (–¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è)
        if "success_stories" in context_data:
            formatted_sections.append("\nüåü **–ò–°–¢–û–†–ò–ò –£–°–ü–ï–•–ê:**")
            for story in context_data["success_stories"]:
                formatted_sections.append(f"‚Ä¢ {story['title']}")

        # –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è
        if "communication_style" in context_data:
            style = context_data["communication_style"]
            formatted_sections.append(
                f"\nüé≠ **–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:**\n"
                f"‚Ä¢ –¢–æ–Ω: {style['style']}\n"
                f"‚Ä¢ –û–±—Ä–∞—â–µ–Ω–∏–µ: –Ω–∞ '{style['address']}'\n"
                f"‚Ä¢ –ü–æ–¥—Ö–æ–¥: {style['approach']}"
            )

        # –õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è
        if "user_city" in context_data:
            formatted_sections.append(
                f"\nüìç **–õ–û–ö–ê–õ–ò–ó–ê–¶–ò–Ø:** –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–∑ –≥–æ—Ä–æ–¥–∞ {context_data['user_city']}"
            )

        # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        if "personalized_categories" in context_data:
            cats = context_data["personalized_categories"]
            formatted_sections.append(
                f"\nüéØ **–†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò:** {', '.join(cats)}"
            )

        return "\n".join(formatted_sections)

    # =====================================================
    # –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
    # =====================================================

    def _get_local_recommendations(self, city: str) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        # –ó–¥–µ—Å—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–µ–∞–ª—å–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        local_cache = {
            "–∞–ª–º–∞—Ç—ã": ["–ì–æ—Ä–Ω—ã–µ –∫–ª—É–±—ã", "IT-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞", "–¢–≤–æ—Ä—á–µ—Å–∫–∏–µ —Å—Ç—É–¥–∏–∏"],
            "–∞—Å—Ç–∞–Ω–∞": ["–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª—É–±—ã", "–ë–∏–∑–Ω–µ—Å —Å–æ–æ–±—â–µ—Å—Ç–≤–∞", "–°–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ —Ñ–µ–¥–µ—Ä–∞—Ü–∏–∏"],
            "—à—ã–º–∫–µ–Ω—Ç": ["–ö—É–ª—å—Ç—É—Ä–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞", "–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –∫–ª—É–±—ã", "–°–µ–º–µ–π–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è"]
        }
        return local_cache.get(city.lower(), ["–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞"])

    def _map_interests_to_categories(self, interests: List[str]) -> List[str]:
        """–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å—ã –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
        category_mapping = {
            "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ": "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è",
            "—Å–ø–æ—Ä—Ç": "–°–ø–æ—Ä—Ç",
            "—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ": "–•–æ–±–±–∏",
            "–±–∏–∑–Ω–µ—Å": "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è",
            "–∏—Å–∫—É—Å—Å—Ç–≤–æ": "–•–æ–±–±–∏",
            "—Ñ–∏—Ç–Ω–µ—Å": "–°–ø–æ—Ä—Ç",
            "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥": "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è",
            "–º—É–∑—ã–∫–∞": "–•–æ–±–±–∏"
        }

        categories = []
        for interest in interests:
            category = category_mapping.get(interest.lower())
            if category and category not in categories:
                categories.append(category)

        return categories or ["–í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"]

    def _analyze_conversation_history(self, history: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
        if not history:
            return {}

        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        recent_messages = history[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º
        topics = []
        for msg in recent_messages:
            if "–∫–ª—É–±" in msg.get("content", "").lower():
                topics.append("club_interest")
            if "—Å–æ–∑–¥–∞—Ç—å" in msg.get("content", "").lower():
                topics.append("creation_intent")

        return {
            "detected_topics": topics,
            "message_count": len(history),
            "last_interaction": max(msg.get("timestamp", "") for msg in recent_messages)
        }

    def _get_fallback_context(self, query: str, agent_type: str) -> Dict[str, Any]:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
        return {
            "success": False,
            "context": f"ü§ñ –ò–ò-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã '–¶–ï–ù–¢–† –°–û–ë–´–¢–ò–ô'.\n–†–∞–±–æ—Ç–∞—é –≤ —Ä–µ–∂–∏–º–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.",
            "intent": {"primary_intent": "general", "confidence": 0.5},
            "sources": ["fallback"],
            "error": "RAG system temporarily unavailable"
        }

    # =====================================================
    # –£–ü–†–ê–í–õ–ï–ù–ò–ï –ö–ê–ß–ï–°–¢–í–û–ú
    # =====================================================

    def validate_context_quality(self, context: Dict[str, Any], query: str) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        validation_score = 0
        max_score = 100
        issues = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        if "platform_info" in context.get("context", ""):
            validation_score += 20
        else:
            issues.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        query_words = set(query.lower().split())
        context_words = set(context.get("context", "").lower().split())
        relevance = len(query_words & context_words) / max(len(query_words), 1)
        validation_score += min(relevance * 30, 30)

        if relevance < 0.3:
            issues.append("–ù–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å—É")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        if "üè¢" in context.get("context", ""):
            validation_score += 20
        else:
            issues.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ–¥ –∞–≥–µ–Ω—Ç–∞
        if "üé≠" in context.get("context", ""):
            validation_score += 15
        else:
            issues.append("–ù–µ—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ–¥ —Ç–∏–ø –∞–≥–µ–Ω—Ç–∞")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã
        context_length = len(context.get("context", ""))
        if context_length > 200:
            validation_score += 15
        else:
            issues.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")

        return {
            "validation_score": validation_score,
            "max_score": max_score,
            "quality_level": "excellent" if validation_score >= 90 else
                            "good" if validation_score >= 75 else
                            "satisfactory" if validation_score >= 60 else "poor",
            "issues": issues,
            "recommendations": self._get_context_recommendations(validation_score, issues)
        }

    def _get_context_recommendations(self, score: float, issues: List[str]) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        recommendations = []

        if score < 75:
            recommendations.append("üîç –£–ª—É—á—à–∏—Ç—å –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

        if "–ù–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å" in "".join(issues):
            recommendations.append("üéØ –£–ª—É—á—à–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–∞–º–µ—Ä–µ–Ω–∏–π")

        if "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è" in issues:
            recommendations.append("üìã –î–æ–±–∞–≤–∏—Ç—å –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")

        if "–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω" in issues:
            recommendations.append("üìù –£–ª—É—á—à–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")

        return recommendations or ["‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞"]


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä RAG —Å–∏—Å—Ç–µ–º—ã
rag_system = RAGSystem()